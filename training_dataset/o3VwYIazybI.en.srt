0
00:00:12,556 --> 00:00:16,573
Our emotions influence
every aspect of our lives,

1
00:00:16,573 --> 00:00:20,149
from our health and how we learn,
to how we do business and make decisions,

2
00:00:20,149 --> 00:00:21,922
big ones and small.

3
00:00:22,672 --> 00:00:26,162
Our emotions also influence
how we connect with one another.

4
00:00:27,132 --> 00:00:31,108
We've evolved to live
in a world like this,

5
00:00:31,108 --> 00:00:35,427
but instead, we're living
more and more of our lives like this --

6
00:00:35,427 --> 00:00:38,561
this is the text message
from my daughter last night --

7
00:00:38,561 --> 00:00:41,301
in a world that's devoid of emotion.

8
00:00:41,301 --> 00:00:43,252
So I'm on a mission to change that.

9
00:00:43,252 --> 00:00:47,343
I want to bring emotions
back into our digital experiences.

10
00:00:48,223 --> 00:00:51,300
I started on this path 15 years ago.

11
00:00:51,300 --> 00:00:53,366
I was a computer scientist in Egypt,

12
00:00:53,366 --> 00:00:57,871
and I had just gotten accepted to
a Ph.D. program at Cambridge University.

13
00:00:57,871 --> 00:00:59,984
So I did something quite unusual

14
00:00:59,984 --> 00:01:04,209
for a young newlywed Muslim Egyptian wife:

15
00:01:05,599 --> 00:01:08,598
With the support of my husband,
who had to stay in Egypt,

16
00:01:08,598 --> 00:01:11,616
I packed my bags and I moved to England.

17
00:01:11,616 --> 00:01:14,844
At Cambridge, thousands of miles
away from home,

18
00:01:14,844 --> 00:01:18,257
I realized I was spending
more hours with my laptop

19
00:01:18,257 --> 00:01:20,486
than I did with any other human.

20
00:01:20,486 --> 00:01:25,339
Yet despite this intimacy, my laptop
had absolutely no idea how I was feeling.

21
00:01:25,339 --> 00:01:28,550
It had no idea if I was happy,

22
00:01:28,550 --> 00:01:31,538
having a bad day, or stressed, confused,

23
00:01:31,538 --> 00:01:34,460
and so that got frustrating.

24
00:01:35,600 --> 00:01:40,831
Even worse, as I communicated
online with my family back home,

25
00:01:41,421 --> 00:01:44,703
I felt that all my emotions
disappeared in cyberspace.

26
00:01:44,703 --> 00:01:49,858
I was homesick, I was lonely,
and on some days I was actually crying,

27
00:01:49,858 --> 00:01:54,786
but all I had to communicate
these emotions was this.

28
00:01:54,786 --> 00:01:56,806
(Laughter)

29
00:01:56,806 --> 00:02:01,780
Today's technology
has lots of I.Q., but no E.Q.;

30
00:02:01,780 --> 00:02:04,956
lots of cognitive intelligence,
but no emotional intelligence.

31
00:02:04,956 --> 00:02:07,153
So that got me thinking,

32
00:02:07,153 --> 00:02:10,777
what if our technology
could sense our emotions?

33
00:02:10,777 --> 00:02:14,853
What if our devices could sense
how we felt and reacted accordingly,

34
00:02:14,853 --> 00:02:17,866
just the way an emotionally
intelligent friend would?

35
00:02:18,666 --> 00:02:22,230
Those questions led me and my team

36
00:02:22,230 --> 00:02:26,607
to create technologies that can read
and respond to our emotions,

37
00:02:26,607 --> 00:02:29,697
and our starting point was the human face.

38
00:02:30,577 --> 00:02:33,750
So our human face happens to be
one of the most powerful channels

39
00:02:33,750 --> 00:02:37,766
that we all use to communicate
social and emotional states,

40
00:02:37,766 --> 00:02:40,776
everything from enjoyment, surprise,

41
00:02:40,776 --> 00:02:44,979
empathy and curiosity.

42
00:02:44,979 --> 00:02:49,907
In emotion science, we call each
facial muscle movement an action unit.

43
00:02:49,907 --> 00:02:52,832
So for example, action unit 12,

44
00:02:52,832 --> 00:02:54,870
it's not a Hollywood blockbuster,

45
00:02:54,870 --> 00:02:58,312
it is actually a lip corner pull,
which is the main component of a smile.

46
00:02:58,312 --> 00:03:01,300
Try it everybody. Let's get
some smiles going on.

47
00:03:01,300 --> 00:03:03,954
Another example is action unit 4.
It's the brow furrow.

48
00:03:03,954 --> 00:03:06,192
It's when you draw your eyebrows together

49
00:03:06,192 --> 00:03:08,459
and you create all
these textures and wrinkles.

50
00:03:08,459 --> 00:03:12,754
We don't like them, but it's
a strong indicator of a negative emotion.

51
00:03:12,754 --> 00:03:14,960
So we have about 45 of these action units,

52
00:03:14,960 --> 00:03:18,350
and they combine to express
hundreds of emotions.

53
00:03:18,350 --> 00:03:22,251
Teaching a computer to read
these facial emotions is hard,

54
00:03:22,251 --> 00:03:25,223
because these action units,
they can be fast, they're subtle,

55
00:03:25,223 --> 00:03:27,777
and they combine in many different ways.

56
00:03:27,777 --> 00:03:31,515
So take, for example,
the smile and the smirk.

57
00:03:31,515 --> 00:03:35,268
They look somewhat similar,
but they mean very different things.

58
00:03:35,268 --> 00:03:36,986
(Laughter)

59
00:03:36,986 --> 00:03:39,990
So the smile is positive,

60
00:03:39,990 --> 00:03:41,260
a smirk is often negative.

61
00:03:41,260 --> 00:03:45,136
Sometimes a smirk
can make you become famous.

62
00:03:45,136 --> 00:03:47,960
But seriously, it's important
for a computer to be able

63
00:03:47,960 --> 00:03:50,815
to tell the difference
between the two expressions.

64
00:03:50,815 --> 00:03:52,627
So how do we do that?

65
00:03:52,627 --> 00:03:54,414
We give our algorithms

66
00:03:54,414 --> 00:03:58,524
tens of thousands of examples
of people we know to be smiling,

67
00:03:58,524 --> 00:04:01,589
from different ethnicities, ages, genders,

68
00:04:01,589 --> 00:04:04,400
and we do the same for smirks.

69
00:04:04,400 --> 00:04:05,954
And then, using deep learning,

70
00:04:05,954 --> 00:04:08,810
the algorithm looks for all these
textures and wrinkles

71
00:04:08,810 --> 00:04:11,390
and shape changes on our face,

72
00:04:11,390 --> 00:04:14,592
and basically learns that all smiles
have common characteristics,

73
00:04:14,592 --> 00:04:17,773
all smirks have subtly
different characteristics.

74
00:04:17,773 --> 00:04:20,141
And the next time it sees a new face,

75
00:04:20,141 --> 00:04:22,440
it essentially learns that

76
00:04:22,440 --> 00:04:25,473
this face has the same
characteristics of a smile,

77
00:04:25,473 --> 00:04:29,751
and it says, "Aha, I recognize this.
This is a smile expression."

78
00:04:30,381 --> 00:04:33,181
So the best way to demonstrate
how this technology works

79
00:04:33,181 --> 00:04:35,317
is to try a live demo,

80
00:04:35,317 --> 00:04:39,230
so I need a volunteer,
preferably somebody with a face.

81
00:04:39,230 --> 00:04:41,564
(Laughter)

82
00:04:41,564 --> 00:04:44,335
Cloe's going to be our volunteer today.

83
00:04:45,325 --> 00:04:49,783
So over the past five years, we've moved
from being a research project at MIT

84
00:04:49,783 --> 00:04:50,939
to a company,

85
00:04:50,939 --> 00:04:54,131
where my team has worked really hard
to make this technology work,

86
00:04:54,131 --> 00:04:56,540
as we like to say, in the wild.

87
00:04:56,540 --> 00:04:59,210
And we've also shrunk it so that
the core emotion engine

88
00:04:59,210 --> 00:05:02,530
works on any mobile device
with a camera, like this iPad.

89
00:05:02,530 --> 00:05:05,316
So let's give this a try.

90
00:05:06,756 --> 00:05:10,680
As you can see, the algorithm
has essentially found Cloe's face,

91
00:05:10,680 --> 00:05:12,372
so it's this white bounding box,

92
00:05:12,372 --> 00:05:14,943
and it's tracking the main
feature points on her face,

93
00:05:14,943 --> 00:05:17,799
so her eyebrows, her eyes,
her mouth and her nose.

94
00:05:17,799 --> 00:05:20,786
The question is,
can it recognize her expression?

95
00:05:20,786 --> 00:05:22,457
So we're going to test the machine.

96
00:05:22,457 --> 00:05:26,643
So first of all, give me your poker face.
Yep, awesome. (Laughter)

97
00:05:26,643 --> 00:05:29,456
And then as she smiles,
this is a genuine smile, it's great.

98
00:05:29,456 --> 00:05:31,756
So you can see the green bar
go up as she smiles.

99
00:05:31,756 --> 00:05:32,978
Now that was a big smile.

100
00:05:32,978 --> 00:05:36,021
Can you try a subtle smile
to see if the computer can recognize?

101
00:05:36,021 --> 00:05:38,352
It does recognize subtle smiles as well.

102
00:05:38,352 --> 00:05:40,477
We've worked really hard
to make that happen.

103
00:05:40,477 --> 00:05:43,439
And then eyebrow raised,
indicator of surprise.

104
00:05:43,439 --> 00:05:47,688
Brow furrow, which is
an indicator of confusion.

105
00:05:47,688 --> 00:05:51,695
Frown. Yes, perfect.

106
00:05:51,695 --> 00:05:55,188
So these are all the different
action units. There's many more of them.

107
00:05:55,188 --> 00:05:57,220
This is just a slimmed-down demo.

108
00:05:57,220 --> 00:06:00,368
But we call each reading
an emotion data point,

109
00:06:00,368 --> 00:06:03,337
and then they can fire together
to portray different emotions.

110
00:06:03,337 --> 00:06:07,990
So on the right side of the demo --
look like you're happy.

111
00:06:07,990 --> 00:06:09,444
So that's joy. Joy fires up.

112
00:06:09,444 --> 00:06:11,371
And then give me a disgust face.

113
00:06:11,371 --> 00:06:15,643
Try to remember what it was like
when Zayn left One Direction.

114
00:06:15,643 --> 00:06:17,153
(Laughter)

115
00:06:17,153 --> 00:06:21,495
Yeah, wrinkle your nose. Awesome.

116
00:06:21,495 --> 00:06:25,226
And the valence is actually quite
negative, so you must have been a big fan.

117
00:06:25,226 --> 00:06:27,926
So valence is how positive
or negative an experience is,

118
00:06:27,926 --> 00:06:30,712
and engagement is how
expressive she is as well.

119
00:06:30,712 --> 00:06:34,126
So imagine if Cloe had access
to this real-time emotion stream,

120
00:06:34,126 --> 00:06:36,935
and she could share it
with anybody she wanted to.

121
00:06:36,935 --> 00:06:39,858
Thank you.

122
00:06:39,858 --> 00:06:44,479
(Applause)

123
00:06:45,749 --> 00:06:51,019
So, so far, we have amassed
12 billion of these emotion data points.

124
00:06:51,019 --> 00:06:53,630
It's the largest emotion
database in the world.

125
00:06:53,630 --> 00:06:56,593
We've collected it
from 2,9 million face videos,

126
00:06:56,593 --> 00:06:59,193
people who have agreed
to share their emotions with us,

127
00:06:59,193 --> 00:07:02,398
and from 75 countries around the world.

128
00:07:02,398 --> 00:07:04,113
It's growing every day.

129
00:07:04,603 --> 00:07:06,670
It blows my mind away

130
00:07:06,670 --> 00:07:09,865
that we can now quantify something
as personal as our emotions,

131
00:07:09,865 --> 00:07:12,100
and we can do it at this scale.

132
00:07:12,100 --> 00:07:14,277
So what have we learned to date?

133
00:07:15,057 --> 00:07:17,388
Gender.

134
00:07:17,388 --> 00:07:21,034
Our data confirms something
that you might suspect.

135
00:07:21,034 --> 00:07:22,891
Women are more expressive than men.

136
00:07:22,891 --> 00:07:25,574
Not only do they smile more,
their smiles last longer,

137
00:07:25,574 --> 00:07:28,478
and we can now really quantify
what it is that men and women

138
00:07:28,478 --> 00:07:30,614
respond to differently.

139
00:07:30,614 --> 00:07:32,904
Let's do culture: So in the United States,

140
00:07:32,904 --> 00:07:36,108
women are 40 percent
more expressive than men,

141
00:07:36,108 --> 00:07:39,753
but curiously, we don't see any difference
in the U.K. between men and women.

142
00:07:39,753 --> 00:07:42,259
(Laughter)

143
00:07:43,296 --> 00:07:47,323
Age: People who are 50 years and older

144
00:07:47,323 --> 00:07:50,759
are 25 percent more emotive
than younger people.

145
00:07:51,899 --> 00:07:55,751
Women in their 20s smile a lot more
than men the same age,

146
00:07:55,751 --> 00:07:59,590
perhaps a necessity for dating.

147
00:07:59,590 --> 00:08:02,207
But perhaps what surprised us
the most about this data

148
00:08:02,207 --> 00:08:05,410
is that we happen
to be expressive all the time,

149
00:08:05,410 --> 00:08:08,243
even when we are sitting
in front of our devices alone,

150
00:08:08,243 --> 00:08:11,517
and it's not just when we're watching
cat videos on Facebook.

151
00:08:12,217 --> 00:08:15,227
We are expressive when we're emailing,
texting, shopping online,

152
00:08:15,227 --> 00:08:17,527
or even doing our taxes.

153
00:08:17,527 --> 00:08:19,919
Where is this data used today?

154
00:08:19,919 --> 00:08:22,682
In understanding how we engage with media,

155
00:08:22,682 --> 00:08:25,166
so understanding virality
and voting behavior;

156
00:08:25,166 --> 00:08:27,906
and also empowering
or emotion-enabling technology,

157
00:08:27,906 --> 00:08:32,527
and I want to share some examples
that are especially close to my heart.

158
00:08:33,197 --> 00:08:36,265
Emotion-enabled wearable glasses
can help individuals

159
00:08:36,265 --> 00:08:39,493
who are visually impaired
read the faces of others,

160
00:08:39,493 --> 00:08:43,680
and it can help individuals
on the autism spectrum interpret emotion,

161
00:08:43,680 --> 00:08:46,458
something that they really struggle with.

162
00:08:47,918 --> 00:08:50,777
In education, imagine
if your learning apps

163
00:08:50,777 --> 00:08:53,587
sense that you're confused and slow down,

164
00:08:53,587 --> 00:08:55,444
or that you're bored, so it's sped up,

165
00:08:55,444 --> 00:08:58,413
just like a great teacher
would in a classroom.

166
00:08:59,043 --> 00:09:01,644
What if your wristwatch tracked your mood,

167
00:09:01,644 --> 00:09:04,337
or your car sensed that you're tired,

168
00:09:04,337 --> 00:09:06,885
or perhaps your fridge
knows that you're stressed,

169
00:09:06,885 --> 00:09:12,951
so it auto-locks to prevent you
from binge eating. (Laughter)

170
00:09:12,951 --> 00:09:15,668
I would like that, yeah.

171
00:09:15,668 --> 00:09:17,595
What if, when I was in Cambridge,

172
00:09:17,595 --> 00:09:19,908
I had access to my real-time
emotion stream,

173
00:09:19,908 --> 00:09:23,437
and I could share that with my family
back home in a very natural way,

174
00:09:23,437 --> 00:09:27,408
just like I would've if we were all
in the same room together?

175
00:09:27,408 --> 00:09:30,550
I think five years down the line,

176
00:09:30,550 --> 00:09:32,887
all our devices are going
to have an emotion chip,

177
00:09:32,887 --> 00:09:36,951
and we won't remember what it was like
when we couldn't just frown at our device

178
00:09:36,951 --> 00:09:41,200
and our device would say, "Hmm,
you didn't like that, did you?"

179
00:09:41,200 --> 00:09:44,961
Our biggest challenge is that there are
so many applications of this technology,

180
00:09:44,961 --> 00:09:47,864
my team and I realize that we can't
build them all ourselves,

181
00:09:47,864 --> 00:09:51,360
so we've made this technology available
so that other developers

182
00:09:51,360 --> 00:09:53,474
can get building and get creative.

183
00:09:53,474 --> 00:09:57,560
We recognize that
there are potential risks

184
00:09:57,560 --> 00:09:59,627
and potential for abuse,

185
00:09:59,627 --> 00:10:02,576
but personally, having spent
many years doing this,

186
00:10:02,576 --> 00:10:05,548
I believe that the benefits to humanity

187
00:10:05,548 --> 00:10:07,823
from having emotionally
intelligent technology

188
00:10:07,823 --> 00:10:11,399
far outweigh the potential for misuse.

189
00:10:11,399 --> 00:10:13,930
And I invite you all to be
part of the conversation.

190
00:10:13,930 --> 00:10:16,484
The more people who know
about this technology,

191
00:10:16,484 --> 00:10:19,661
the more we can all have a voice
in how it's being used.

192
00:10:21,081 --> 00:10:25,655
So as more and more
of our lives become digital,

193
00:10:25,655 --> 00:10:29,153
we are fighting a losing battle
trying to curb our usage of devices

194
00:10:29,153 --> 00:10:31,382
in order to reclaim our emotions.

195
00:10:32,622 --> 00:10:36,536
So what I'm trying to do instead
is to bring emotions into our technology

196
00:10:36,536 --> 00:10:38,765
and make our technologies more responsive.

197
00:10:38,765 --> 00:10:41,435
So I want those devices
that have separated us

198
00:10:41,435 --> 00:10:43,897
to bring us back together.

199
00:10:43,897 --> 00:10:48,485
And by humanizing technology,
we have this golden opportunity

200
00:10:48,485 --> 00:10:51,782
to reimagine how we
connect with machines,

201
00:10:51,782 --> 00:10:56,263
and therefore, how we, as human beings,

202
00:10:56,263 --> 00:10:58,167
connect with one another.

203
00:10:58,167 --> 00:11:00,327
Thank you.

204
00:11:00,327 --> 00:11:03,640
(Applause)
