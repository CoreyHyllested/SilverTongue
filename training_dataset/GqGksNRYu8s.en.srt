0
00:00:12,760 --> 00:00:15,320
Let's talk about trust.

1
00:00:16,240 --> 00:00:19,736
We all know trust is fundamental,

2
00:00:19,760 --> 00:00:22,376
but when it comes to trusting people,

3
00:00:22,400 --> 00:00:25,160
something profound is happening.

4
00:00:25,800 --> 00:00:27,056
Please raise your hand

5
00:00:27,080 --> 00:00:31,400
if you have ever been
a host or a guest on Airbnb.

6
00:00:32,400 --> 00:00:35,616
Wow. That's a lot of you.

7
00:00:35,640 --> 00:00:37,080
Who owns Bitcoin?

8
00:00:38,640 --> 00:00:39,896
Still a lot of you. OK.

9
00:00:39,920 --> 00:00:42,616
And please raise your hand
if you've ever used Tinder

10
00:00:42,640 --> 00:00:44,256
to help you find a mate.

11
00:00:44,280 --> 00:00:46,096
(Laughter)

12
00:00:46,120 --> 00:00:49,496
This one's really hard to count
because you're kind of going like this.

13
00:00:49,520 --> 00:00:51,336
(Laughter)

14
00:00:51,360 --> 00:00:54,136
These are all examples of how technology

15
00:00:54,160 --> 00:00:56,256
is creating new mechanisms

16
00:00:56,280 --> 00:01:02,296
that are enabling us to trust
unknown people, companies and ideas.

17
00:01:02,320 --> 00:01:04,336
And yet at the same time,

18
00:01:04,360 --> 00:01:05,896
trust in institutions --

19
00:01:05,920 --> 00:01:08,856
banks, governments and even churches --

20
00:01:08,880 --> 00:01:10,256
is collapsing.

21
00:01:10,280 --> 00:01:12,496
So what's happening here,

22
00:01:12,520 --> 00:01:14,280
and who do you trust?

23
00:01:14,800 --> 00:01:18,696
Let's start in France with a platform --
with a company, I should say --

24
00:01:18,720 --> 00:01:20,856
with a rather funny-sounding name,

25
00:01:20,880 --> 00:01:22,136
BlaBlaCar.

26
00:01:22,160 --> 00:01:25,776
It's a platform that matches
drivers and passengers

27
00:01:25,800 --> 00:01:29,816
who want to share
long-distance journeys together.

28
00:01:29,840 --> 00:01:34,056
The average ride taken is 320 kilometers.

29
00:01:34,080 --> 00:01:38,680
So it's a good idea
to choose your fellow travelers wisely.

30
00:01:39,320 --> 00:01:43,296
Social profiles and reviews
help people make a choice.

31
00:01:43,320 --> 00:01:48,336
You can see if someone's a smoker,
you can see what kind of music they like,

32
00:01:48,360 --> 00:01:51,960
you can see if they're going to bring
their dog along for the ride.

33
00:01:52,440 --> 00:01:56,016
But it turns out
that the key social identifier

34
00:01:56,040 --> 00:01:58,656
is how much you're going
to talk in the car.

35
00:01:58,680 --> 00:02:00,496
(Laughter)

36
00:02:00,520 --> 00:02:02,136
Bla, not a lot,

37
00:02:02,160 --> 00:02:04,456
bla bla, you want a nice bit of chitchat,

38
00:02:04,480 --> 00:02:08,216
and bla bla bla, you're not going
to stop talking the entire way

39
00:02:08,240 --> 00:02:09,696
from London to Paris.

40
00:02:09,720 --> 00:02:12,016
(Laughter)

41
00:02:12,040 --> 00:02:15,056
It's remarkable, right,
that this idea works at all,

42
00:02:15,080 --> 00:02:18,936
because it's counter to the lesson
most of us were taught as a child:

43
00:02:18,960 --> 00:02:21,280
never get in a car with a stranger.

44
00:02:21,680 --> 00:02:26,816
And yet, BlaBlaCar transports
more than four million people

45
00:02:26,840 --> 00:02:28,080
every single month.

46
00:02:28,880 --> 00:02:31,216
To put that in context,
that's more passengers

47
00:02:31,240 --> 00:02:34,720
than the Eurostar
or JetBlue airlines carry.

48
00:02:35,360 --> 00:02:39,496
BlaBlaCar is a beautiful illustration
of how technology is enabling

49
00:02:39,520 --> 00:02:43,120
millions of people across the world
to take a trust leap.

50
00:02:43,560 --> 00:02:49,816
A trust leap happens when we take the risk
to do something new or different

51
00:02:49,840 --> 00:02:51,880
to the way that we've always done it.

52
00:02:52,440 --> 00:02:55,000
Let's try to visualize this together.

53
00:02:55,360 --> 00:02:58,520
OK. I want you to close your eyes.

54
00:02:59,320 --> 00:03:02,376
There is a man staring at me
with his eyes wide open.

55
00:03:02,400 --> 00:03:04,856
I'm on this big red circle. I can see.

56
00:03:04,880 --> 00:03:06,296
So close your eyes.

57
00:03:06,320 --> 00:03:09,176
(Laughter) (Applause)

58
00:03:09,200 --> 00:03:10,456
I'll do it with you.

59
00:03:10,480 --> 00:03:13,496
And I want you to imagine
there exists a gap

60
00:03:13,520 --> 00:03:16,080
between you and something unknown.

61
00:03:16,760 --> 00:03:19,616
That unknown can be
someone you've just met.

62
00:03:19,640 --> 00:03:21,736
It can be a place you've never been to.

63
00:03:21,760 --> 00:03:25,136
It can be something
you've never tried before.

64
00:03:25,160 --> 00:03:26,376
You got it?

65
00:03:26,400 --> 00:03:28,496
OK. You can open your eyes now.

66
00:03:28,520 --> 00:03:31,856
For you to leap from a place of certainty,

67
00:03:31,880 --> 00:03:35,456
to take a chance on that someone
or something unknown,

68
00:03:35,480 --> 00:03:38,816
you need a force to pull you over the gap,

69
00:03:38,840 --> 00:03:41,680
and that remarkable force is trust.

70
00:03:42,560 --> 00:03:46,176
Trust is an elusive concept,

71
00:03:46,200 --> 00:03:49,576
and yet we depend on it
for our lives to function.

72
00:03:49,600 --> 00:03:51,856
I trust my children

73
00:03:51,880 --> 00:03:54,736
when they say they're going
to turn the lights out at night.

74
00:03:54,760 --> 00:03:57,976
I trusted the pilot
who flew me here to keep me safe.

75
00:03:58,000 --> 00:04:00,816
It's a word we use a lot,

76
00:04:00,840 --> 00:04:03,256
without always thinking
about what it really means

77
00:04:03,280 --> 00:04:06,656
and how it works in different
contexts of our lives.

78
00:04:06,680 --> 00:04:10,296
There are, in fact,
hundreds of definitions of trust,

79
00:04:10,320 --> 00:04:14,896
and most can be reduced
to some kind of risk assessment

80
00:04:14,920 --> 00:04:17,680
of how likely it is
that things will go right.

81
00:04:18,120 --> 00:04:20,696
But I don't like this definition of trust,

82
00:04:20,720 --> 00:04:25,016
because it makes trust
sound rational and predictable,

83
00:04:25,040 --> 00:04:27,616
and it doesn't really get
to the human essence

84
00:04:27,640 --> 00:04:29,576
of what it enables us to do

85
00:04:29,600 --> 00:04:31,576
and how it empowers us

86
00:04:31,600 --> 00:04:33,696
to connect with other people.

87
00:04:33,720 --> 00:04:35,776
So I define trust a little differently.

88
00:04:35,800 --> 00:04:41,240
I define trust as a confident
relationship to the unknown.

89
00:04:41,920 --> 00:04:44,016
Now, when you view trust
through this lens,

90
00:04:44,040 --> 00:04:47,696
it starts to explain
why it has the unique capacity

91
00:04:47,720 --> 00:04:50,816
to enable us to cope with uncertainty,

92
00:04:50,840 --> 00:04:53,856
to place our faith in strangers,

93
00:04:53,880 --> 00:04:55,760
to keep moving forward.

94
00:04:56,400 --> 00:04:59,176
Human beings are remarkable

95
00:04:59,200 --> 00:05:00,880
at taking trust leaps.

96
00:05:01,400 --> 00:05:04,376
Do you remember the first time
you put your credit card details

97
00:05:04,400 --> 00:05:05,616
into a website?

98
00:05:05,640 --> 00:05:06,976
That's a trust leap.

99
00:05:07,000 --> 00:05:09,936
I distinctly remember telling my dad

100
00:05:09,960 --> 00:05:15,216
that I wanted to buy a navy blue
secondhand Peugeot on eBay,

101
00:05:15,240 --> 00:05:16,896
and he rightfully pointed out

102
00:05:16,920 --> 00:05:19,296
that the seller's name
was "Invisible Wizard"

103
00:05:19,320 --> 00:05:22,416
and that this probably
was not such a good idea.

104
00:05:22,440 --> 00:05:24,136
(Laughter)

105
00:05:24,160 --> 00:05:27,576
So my work, my research
focuses on how technology

106
00:05:27,600 --> 00:05:30,256
is transforming
the social glue of society,

107
00:05:30,280 --> 00:05:31,936
trust between people,

108
00:05:31,960 --> 00:05:34,216
and it's a fascinating area to study,

109
00:05:34,240 --> 00:05:37,616
because there's still
so much we do not know.

110
00:05:37,640 --> 00:05:42,736
For instance, do men and women
trust differently in digital environments?

111
00:05:42,760 --> 00:05:47,656
Does the way we build trust
face-to-face translate online?

112
00:05:47,680 --> 00:05:49,616
Does trust transfer?

113
00:05:49,640 --> 00:05:52,336
So if you trust finding a mate on Tinder,

114
00:05:52,360 --> 00:05:55,720
are you more likely
to trust finding a ride on BlaBlaCar?

115
00:05:56,440 --> 00:05:59,696
But from studying hundreds
of networks and marketplaces,

116
00:05:59,720 --> 00:06:02,536
there is a common pattern
that people follow,

117
00:06:02,560 --> 00:06:05,216
and I call it "climbing the trust stack."

118
00:06:05,240 --> 00:06:08,440
Let me use BlaBlaCar
as an example to bring it to life.

119
00:06:09,080 --> 00:06:10,376
On the first level,

120
00:06:10,400 --> 00:06:12,576
you have to trust the idea.

121
00:06:12,600 --> 00:06:13,816
So you have to trust

122
00:06:13,840 --> 00:06:17,240
the idea of ride-sharing
is safe and worth trying.

123
00:06:17,640 --> 00:06:22,336
The second level is about having
confidence in the platform,

124
00:06:22,360 --> 00:06:26,496
that BlaBlaCar will help you
if something goes wrong.

125
00:06:26,520 --> 00:06:30,176
And the third level is about
using little bits of information

126
00:06:30,200 --> 00:06:33,680
to decide whether
the other person is trustworthy.

127
00:06:34,200 --> 00:06:36,816
Now, the first time
we climb the trust stack,

128
00:06:36,840 --> 00:06:40,096
it feels weird, even risky,

129
00:06:40,120 --> 00:06:45,096
but we get to a point
where these ideas seem totally normal.

130
00:06:45,120 --> 00:06:47,416
Our behaviors transform,

131
00:06:47,440 --> 00:06:49,416
often relatively quickly.

132
00:06:49,440 --> 00:06:54,240
In other words, trust enables
change and innovation.

133
00:06:55,280 --> 00:06:58,696
So an idea that intrigued me,
and I'd like you to consider,

134
00:06:58,720 --> 00:07:01,256
is whether we can better understand

135
00:07:01,280 --> 00:07:05,456
major waves of disruption and change
in individuals in society

136
00:07:05,480 --> 00:07:07,536
through the lens of trust.

137
00:07:07,560 --> 00:07:10,856
Well, it turns out
that trust has only evolved

138
00:07:10,880 --> 00:07:15,536
in three significant chapters
throughout the course of human history:

139
00:07:15,560 --> 00:07:17,776
local, institutional

140
00:07:17,800 --> 00:07:20,200
and what we're now entering, distributed.

141
00:07:20,680 --> 00:07:23,016
So for a long time,

142
00:07:23,040 --> 00:07:24,296
until the mid-1800s,

143
00:07:24,320 --> 00:07:28,256
trust was built
around tight-knit relationships.

144
00:07:28,280 --> 00:07:30,296
So say I lived in a village

145
00:07:30,320 --> 00:07:32,896
with the first five rows of this audience,

146
00:07:32,920 --> 00:07:34,856
and we all knew one another,

147
00:07:34,880 --> 00:07:37,776
and say I wanted to borrow money.

148
00:07:37,800 --> 00:07:40,776
The man who had his eyes wide open,
he might lend it to me,

149
00:07:40,800 --> 00:07:42,896
and if I didn't pay him back,

150
00:07:42,920 --> 00:07:44,576
you'd all know I was dodgy.

151
00:07:44,600 --> 00:07:46,256
I would get a bad reputation,

152
00:07:46,280 --> 00:07:49,336
and you would refuse
to do business with me in the future.

153
00:07:49,360 --> 00:07:53,576
Trust was mostly local
and accountability-based.

154
00:07:53,600 --> 00:07:54,936
In the mid-19th century,

155
00:07:54,960 --> 00:07:58,376
society went through
a tremendous amount of change.

156
00:07:58,400 --> 00:08:02,176
People moved to fast-growing cities
such as London and San Francisco,

157
00:08:02,200 --> 00:08:07,056
and a local banker here
was replaced by large corporations

158
00:08:07,080 --> 00:08:09,976
that didn't know us as individuals.

159
00:08:10,000 --> 00:08:11,976
We started to place our trust

160
00:08:12,000 --> 00:08:15,576
into black box systems of authority,

161
00:08:15,600 --> 00:08:19,896
things like legal contracts
and regulation and insurance,

162
00:08:19,920 --> 00:08:23,936
and less trust directly in other people.

163
00:08:23,960 --> 00:08:27,816
Trust became institutional
and commission-based.

164
00:08:27,840 --> 00:08:32,656
It's widely talked about how trust
in institutions and many corporate brands

165
00:08:32,680 --> 00:08:36,416
has been steadily declining
and continues to do so.

166
00:08:36,440 --> 00:08:42,056
I am constantly stunned
by major breaches of trust:

167
00:08:42,080 --> 00:08:44,576
the News Corp phone hacking,

168
00:08:44,600 --> 00:08:47,416
the Volkswagen emissions scandal,

169
00:08:47,440 --> 00:08:50,775
the widespread abuse
in the Catholic Church,

170
00:08:50,799 --> 00:08:54,015
the fact that only one measly banker

171
00:08:54,039 --> 00:08:57,336
went to jail after the great
financial crisis,

172
00:08:57,360 --> 00:08:59,416
or more recently the Panama Papers

173
00:08:59,440 --> 00:09:04,576
that revealed how the rich
can exploit offshore tax regimes.

174
00:09:04,600 --> 00:09:07,056
And the thing that really surprises me

175
00:09:07,080 --> 00:09:11,096
is why do leaders find it so hard

176
00:09:11,120 --> 00:09:14,296
to apologize, I mean sincerely apologize,

177
00:09:14,320 --> 00:09:16,480
when our trust is broken?

178
00:09:17,360 --> 00:09:21,496
It would be easy to conclude
that institutional trust isn't working

179
00:09:21,520 --> 00:09:23,016
because we are fed up

180
00:09:23,040 --> 00:09:25,936
with the sheer audacity
of dishonest elites,

181
00:09:25,960 --> 00:09:27,936
but what's happening now

182
00:09:27,960 --> 00:09:33,576
runs deeper than the rampant questioning
of the size and structure of institutions.

183
00:09:33,600 --> 00:09:35,616
We're starting to realize

184
00:09:35,640 --> 00:09:37,416
that institutional trust

185
00:09:37,440 --> 00:09:40,416
wasn't designed for the digital age.

186
00:09:40,440 --> 00:09:44,096
Conventions of how trust is built,

187
00:09:44,120 --> 00:09:46,456
managed, lost and repaired --

188
00:09:46,480 --> 00:09:48,976
in brands, leaders and entire systems --

189
00:09:49,000 --> 00:09:51,000
is being turned upside down.

190
00:09:51,760 --> 00:09:53,856
Now, this is exciting,

191
00:09:53,880 --> 00:09:55,416
but it's frightening,

192
00:09:55,440 --> 00:09:58,136
because it forces many of us
to have to rethink

193
00:09:58,160 --> 00:10:02,856
how trust is built and destroyed
with our customers, with our employees,

194
00:10:02,880 --> 00:10:04,360
even our loved ones.

195
00:10:05,800 --> 00:10:11,976
The other day, I was talking to the CEO
of a leading international hotel brand,

196
00:10:12,000 --> 00:10:15,240
and as is often the case,
we got onto the topic of Airbnb.

197
00:10:15,840 --> 00:10:20,936
And he admitted to me
that he was perplexed by their success.

198
00:10:20,960 --> 00:10:23,096
He was perplexed at how a company

199
00:10:23,120 --> 00:10:27,296
that depends on the willingness
of strangers to trust one another

200
00:10:27,320 --> 00:10:31,280
could work so well across 191 countries.

201
00:10:31,920 --> 00:10:35,056
So I said to him
that I had a confession to make,

202
00:10:35,080 --> 00:10:37,056
and he looked at me a bit strangely,

203
00:10:37,080 --> 00:10:38,456
and I said --

204
00:10:38,480 --> 00:10:40,496
and I'm sure many of you
do this as well --

205
00:10:40,520 --> 00:10:43,016
I don't always bother to hang my towels up

206
00:10:43,040 --> 00:10:45,976
when I'm finished in the hotel,

207
00:10:46,000 --> 00:10:48,640
but I would never do this
as a guest on Airbnb.

208
00:10:49,560 --> 00:10:52,896
And the reason why I would never do this
as a guest on Airbnb

209
00:10:52,920 --> 00:10:56,576
is because guests know
that they'll be rated by hosts,

210
00:10:56,600 --> 00:11:00,336
and that those ratings
are likely to impact their ability

211
00:11:00,360 --> 00:11:02,040
to transact in the future.

212
00:11:02,680 --> 00:11:06,896
It's a simple illustration of how
online trust will change our behaviors

213
00:11:06,920 --> 00:11:08,216
in the real world,

214
00:11:08,240 --> 00:11:10,736
make us more accountable

215
00:11:10,760 --> 00:11:14,200
in ways we cannot yet even imagine.

216
00:11:14,880 --> 00:11:17,936
I am not saying we do not need hotels

217
00:11:17,960 --> 00:11:20,296
or traditional forms of authority.

218
00:11:20,320 --> 00:11:22,416
But what we cannot deny

219
00:11:22,440 --> 00:11:26,696
is that the way trust
flows through society is changing,

220
00:11:26,720 --> 00:11:29,016
and it's creating this big shift

221
00:11:29,040 --> 00:11:30,896
away from the 20th century

222
00:11:30,920 --> 00:11:33,736
that was defined by institutional trust

223
00:11:33,760 --> 00:11:36,256
towards the 21st century

224
00:11:36,280 --> 00:11:38,920
that will be fueled by distributed trust.

225
00:11:39,480 --> 00:11:43,656
Trust is no longer top-down.

226
00:11:43,680 --> 00:11:45,776
It's being unbundled and inverted.

227
00:11:45,800 --> 00:11:48,640
It's no longer opaque and linear.

228
00:11:49,160 --> 00:11:52,136
A new recipe for trust is emerging

229
00:11:52,160 --> 00:11:56,056
that once again
is distributed amongst people

230
00:11:56,080 --> 00:11:58,216
and is accountability-based.

231
00:11:58,240 --> 00:12:01,656
And this shift is only going to accelerate

232
00:12:01,680 --> 00:12:04,416
with the emergence of the blockchain,

233
00:12:04,440 --> 00:12:08,080
the innovative ledger technology
underpinning Bitcoin.

234
00:12:08,800 --> 00:12:11,736
Now let's be honest,

235
00:12:11,760 --> 00:12:15,216
getting our heads around
the way blockchain works

236
00:12:15,240 --> 00:12:16,680
is mind-blowing.

237
00:12:17,720 --> 00:12:20,976
And one of the reasons why
is it involves processing

238
00:12:21,000 --> 00:12:23,656
some pretty complicated concepts

239
00:12:23,680 --> 00:12:25,176
with terrible names.

240
00:12:25,200 --> 00:12:29,696
I mean, cryptographic algorithms
and hash functions,

241
00:12:29,720 --> 00:12:32,776
and people called miners,
who verify transactions --

242
00:12:32,800 --> 00:12:36,376
all that was created
by this mysterious person

243
00:12:36,400 --> 00:12:39,136
or persons called Satoshi Nakamoto.

244
00:12:39,160 --> 00:12:44,816
Now, that is a massive trust leap
that hasn't happened yet.

245
00:12:44,840 --> 00:12:47,896
(Applause)

246
00:12:47,920 --> 00:12:49,376
But let's try to imagine this.

247
00:12:49,400 --> 00:12:53,096
So "The Economist"
eloquently described the blockchain

248
00:12:53,120 --> 00:12:56,776
as the great chain
of being sure about things.

249
00:12:56,800 --> 00:13:01,856
The easiest way I can describe it
is imagine the blocks as spreadsheets,

250
00:13:01,880 --> 00:13:04,856
and they are filled with assets.

251
00:13:04,880 --> 00:13:07,296
So that could be a property title.

252
00:13:07,320 --> 00:13:09,336
It could be a stock trade.

253
00:13:09,360 --> 00:13:12,320
It could be a creative asset,
such as the rights to a song.

254
00:13:12,960 --> 00:13:15,976
Every time something moves

255
00:13:16,000 --> 00:13:19,816
from one place on the register
to somewhere else,

256
00:13:19,840 --> 00:13:22,936
that asset transfer is time-stamped

257
00:13:22,960 --> 00:13:26,376
and publicly recorded on the blockchain.

258
00:13:26,400 --> 00:13:28,280
It's that simple. Right.

259
00:13:28,720 --> 00:13:31,816
So the real implication of the blockchain

260
00:13:31,840 --> 00:13:35,976
is that it removes the need
for any kind of third party,

261
00:13:36,000 --> 00:13:37,336
such as a lawyer,

262
00:13:37,360 --> 00:13:40,816
or a trusted intermediary,
or maybe not a government intermediary

263
00:13:40,840 --> 00:13:42,656
to facilitate the exchange.

264
00:13:42,680 --> 00:13:44,936
So if we go back to the trust stack,

265
00:13:44,960 --> 00:13:47,696
you still have to trust the idea,

266
00:13:47,720 --> 00:13:50,016
you have to trust the platform,

267
00:13:50,040 --> 00:13:52,976
but you don't have to trust
the other person

268
00:13:53,000 --> 00:13:54,936
in the traditional sense.

269
00:13:54,960 --> 00:13:57,456
The implications are huge.

270
00:13:57,480 --> 00:14:01,176
In the same way the internet blew open
the doors to an age of information

271
00:14:01,200 --> 00:14:02,616
available to everyone,

272
00:14:02,640 --> 00:14:06,960
the blockchain will revolutionize
trust on a global scale.

273
00:14:08,240 --> 00:14:12,176
Now, I've waited to the end
intentionally to mention Uber,

274
00:14:12,200 --> 00:14:15,656
because I recognize
that it is a contentious

275
00:14:15,680 --> 00:14:18,296
and widely overused example,

276
00:14:18,320 --> 00:14:21,560
but in the context of a new era of trust,
it's a great case study.

277
00:14:21,920 --> 00:14:26,656
Now, we will see cases of abuse
of distributed trust.

278
00:14:26,680 --> 00:14:30,336
We've already seen this,
and it can go horribly wrong.

279
00:14:30,360 --> 00:14:35,536
I am not surprised that we are seeing
protests from taxi associations

280
00:14:35,560 --> 00:14:36,896
all around the world

281
00:14:36,920 --> 00:14:41,800
trying to get governments to ban Uber
based on claims that it is unsafe.

282
00:14:42,320 --> 00:14:46,696
I happened to be in London
the day that these protests took place,

283
00:14:46,720 --> 00:14:48,696
and I happened to notice a tweet

284
00:14:48,720 --> 00:14:52,336
from Matt Hancock, who is
a British minister for business.

285
00:14:52,360 --> 00:14:53,576
And he wrote,

286
00:14:53,600 --> 00:14:57,576
"Does anyone have details of this
#Uber app everyone's talking about?

287
00:14:57,600 --> 00:14:58,800
(Laughter)

288
00:14:59,880 --> 00:15:02,520
I'd never heard of it until today."

289
00:15:03,560 --> 00:15:06,840
Now, the taxi associations,

290
00:15:07,800 --> 00:15:10,536
they legitimized the first layer
of the trust stack.

291
00:15:10,560 --> 00:15:13,896
They legitimized the idea
that they were trying to eliminate,

292
00:15:13,920 --> 00:15:19,056
and sign-ups increased
by 850 percent in 24 hours.

293
00:15:19,080 --> 00:15:22,336
Now, this is a really strong illustration

294
00:15:22,360 --> 00:15:28,176
of how once a trust shift has happened
around a behavior or an entire sector,

295
00:15:28,200 --> 00:15:30,440
you cannot reverse the story.

296
00:15:31,120 --> 00:15:34,976
Every day, five million people
will take a trust leap

297
00:15:35,000 --> 00:15:36,536
and ride with Uber.

298
00:15:36,560 --> 00:15:39,776
In China, on Didi,
the ride-sharing platform,

299
00:15:39,800 --> 00:15:42,696
11 million rides taken every day.

300
00:15:42,720 --> 00:15:46,336
That's 127 rides per second,

301
00:15:46,360 --> 00:15:49,176
showing that this is
a cross-cultural phenomenon.

302
00:15:49,200 --> 00:15:53,376
And the fascinating thing is
that both drivers and passengers report

303
00:15:53,400 --> 00:15:55,896
that seeing a name

304
00:15:55,920 --> 00:15:58,896
and seeing someone's photo
and their rating

305
00:15:58,920 --> 00:16:01,176
makes them feel safer,

306
00:16:01,200 --> 00:16:02,776
and as you may have experienced,

307
00:16:02,800 --> 00:16:06,760
even behave a little more nicely
in the taxi cab.

308
00:16:07,360 --> 00:16:11,056
Uber and Didi are early
but powerful examples

309
00:16:11,080 --> 00:16:15,056
of how technology
is creating trust between people

310
00:16:15,080 --> 00:16:18,360
in ways and on a scale
never possible before.

311
00:16:19,120 --> 00:16:25,176
Today, many of us are comfortable
getting into cars driven by strangers.

312
00:16:25,200 --> 00:16:29,496
We meet up with someone
we swiped right to be matched with.

313
00:16:29,520 --> 00:16:33,456
We share our homes
with people we do not know.

314
00:16:33,480 --> 00:16:35,840
This is just the beginning,

315
00:16:36,440 --> 00:16:39,016
because the real disruption happening

316
00:16:39,040 --> 00:16:40,976
isn't technological.

317
00:16:41,000 --> 00:16:43,320
It's the trust shift it creates,

318
00:16:43,880 --> 00:16:48,976
and for my part, I want to help people
understand this new era of trust

319
00:16:49,000 --> 00:16:50,656
so that we can get it right

320
00:16:50,680 --> 00:16:54,576
and we can embrace
the opportunities to redesign systems

321
00:16:54,600 --> 00:16:58,696
that are more transparent,
inclusive and accountable.

322
00:16:58,720 --> 00:16:59,976
Thank you very much.

323
00:17:00,000 --> 00:17:02,576
(Applause)

324
00:17:02,600 --> 00:17:03,816
Thank you.

325
00:17:03,840 --> 00:17:07,548
(Applause)
