0
00:00:12,528 --> 00:00:16,477
So in 1885, Karl Benz
invented the automobile.

1
00:00:16,707 --> 00:00:20,469
Later that year, he took it out
for the first public test drive,

2
00:00:20,469 --> 00:00:23,844
and -- true story --
crashed into a wall.

3
00:00:24,184 --> 00:00:26,227
For the last 130 years,

4
00:00:26,227 --> 00:00:30,546
we've been working around that least
reliable part of the car, the driver.

5
00:00:30,546 --> 00:00:31,900
We've made the car stronger.

6
00:00:32,200 --> 00:00:34,748
We've added seat belts,
we've added air bags,

7
00:00:34,748 --> 00:00:38,719
and in the last decade, we've actually
started trying to make the car smarter

8
00:00:38,719 --> 00:00:41,657
to fix that bug, the driver.

9
00:00:41,657 --> 00:00:44,918
Now, today I'm going to talk to you
a little bit about the difference

10
00:00:44,918 --> 00:00:48,726
between patching around the problem
with driver assistance systems

11
00:00:48,726 --> 00:00:51,290
and actually having fully
self-driving cars

12
00:00:51,290 --> 00:00:53,170
and what they can do for the world.

13
00:00:53,170 --> 00:00:56,165
I'm also going to talk to you
a little bit about our car

14
00:00:56,165 --> 00:01:00,164
and allow you to see how it sees the world
and how it reacts and what it does,

15
00:01:00,164 --> 00:01:03,351
but first I'm going to talk
a little bit about the problem.

16
00:01:03,651 --> 00:01:05,299
And it's a big problem:

17
00:01:05,299 --> 00:01:08,388
1,2 million people are killed
on the world's roads every year.

18
00:01:08,388 --> 00:01:12,172
In America alone, 33,000 people
are killed each year.

19
00:01:12,172 --> 00:01:14,200
To put that in perspective,

20
00:01:14,200 --> 00:01:18,997
that's the same as a 737
falling out of the sky every working day.

21
00:01:19,342 --> 00:01:21,128
It's kind of unbelievable.

22
00:01:21,548 --> 00:01:23,846
Cars are sold to us like this,

23
00:01:23,846 --> 00:01:26,563
but really, this is what driving's like.

24
00:01:26,563 --> 00:01:28,722
Right? It's not sunny, it's rainy,

25
00:01:28,722 --> 00:01:31,210
and you want to do anything
other than drive.

26
00:01:31,210 --> 00:01:32,832
And the reason why is this:

27
00:01:32,832 --> 00:01:34,690
Traffic is getting worse.

28
00:01:34,690 --> 00:01:38,196
In America, between 1990 and 2010,

29
00:01:38,196 --> 00:01:41,700
the vehicle miles traveled
increased by 38 percent.

30
00:01:42,213 --> 00:01:44,962
We grew by six percent of roads,

31
00:01:44,962 --> 00:01:46,564
so it's not in your brains.

32
00:01:46,564 --> 00:01:50,840
Traffic really is substantially worse
than it was not very long ago.

33
00:01:50,840 --> 00:01:53,249
And all of this has a very human cost.

34
00:01:53,529 --> 00:01:57,477
So if you take the average commute time
in America, which is about 50 minutes,

35
00:01:57,477 --> 00:02:01,126
you multiply that by the 120 million
workers we have,

36
00:02:01,126 --> 00:02:03,351
that turns out to be
about six billion minutes

37
00:02:03,351 --> 00:02:05,377
wasted in commuting every day.

38
00:02:05,377 --> 00:02:08,204
Now, that's a big number,
so let's put it in perspective.

39
00:02:08,204 --> 00:02:09,978
You take that six billion minutes

40
00:02:09,978 --> 00:02:13,762
and you divide it by the average
life expectancy of a person,

41
00:02:13,762 --> 00:02:16,897
that turns out to be 162 lifetimes

42
00:02:16,897 --> 00:02:19,822
spent every day, wasted,

43
00:02:19,822 --> 00:02:21,866
just getting from A to B.

44
00:02:21,866 --> 00:02:23,596
It's unbelievable.

45
00:02:23,596 --> 00:02:26,440
And then, there are those of us
who don't have the privilege

46
00:02:26,440 --> 00:02:28,112
of sitting in traffic.

47
00:02:28,112 --> 00:02:29,690
So this is Steve.

48
00:02:29,690 --> 00:02:31,455
He's an incredibly capable guy,

49
00:02:31,455 --> 00:02:33,971
but he just happens to be blind,

50
00:02:33,971 --> 00:02:37,188
and that means instead of a 30-minute
drive to work in the morning,

51
00:02:37,188 --> 00:02:41,167
it's a two-hour ordeal
of piecing together bits of public transit

52
00:02:41,167 --> 00:02:43,552
or asking friends and family for a ride.

53
00:02:43,552 --> 00:02:47,221
He doesn't have that same freedom
that you and I have to get around.

54
00:02:47,221 --> 00:02:49,681
We should do something about that.

55
00:02:49,891 --> 00:02:51,648
Now, conventional wisdom would say

56
00:02:51,648 --> 00:02:54,140
that we'll just take
these driver assistance systems

57
00:02:54,140 --> 00:02:57,890
and we'll kind of push them
and incrementally improve them,

58
00:02:57,890 --> 00:03:00,432
and over time, they'll turn
into self-driving cars.

59
00:03:00,432 --> 00:03:02,841
Well, I'm here to tell you
that's like me saying

60
00:03:02,841 --> 00:03:06,898
that if I work really hard at jumping,
one day I'll be able to fly.

61
00:03:06,898 --> 00:03:09,626
We actually need to do
something a little different.

62
00:03:09,626 --> 00:03:12,337
And so I'm going to talk to you
about three different ways

63
00:03:12,337 --> 00:03:15,683
that self-driving systems are different
than driver assistance systems.

64
00:03:15,683 --> 00:03:18,334
And I'm going to start
with some of our own experience.

65
00:03:18,334 --> 00:03:20,587
So back in 2013,

66
00:03:20,587 --> 00:03:23,250
we had the first test
of a self-driving car

67
00:03:23,250 --> 00:03:25,277
where we let regular people use it.

68
00:03:25,277 --> 00:03:27,479
Well, almost regular --
they were 100 Googlers,

69
00:03:27,479 --> 00:03:29,482
but they weren't working on the project.

70
00:03:29,482 --> 00:03:33,103
And we gave them the car and we allowed
them to use it in their daily lives.

71
00:03:33,103 --> 00:03:36,822
But unlike a real self-driving car,
this one had a big asterisk with it:

72
00:03:36,822 --> 00:03:38,326
They had to pay attention,

73
00:03:38,326 --> 00:03:40,959
because this was an experimental vehicle.

74
00:03:40,959 --> 00:03:44,484
We tested it a lot,
but it could still fail.

75
00:03:44,484 --> 00:03:46,543
And so we gave them two hours of training,

76
00:03:46,543 --> 00:03:48,635
we put them in the car,
we let them use it,

77
00:03:48,635 --> 00:03:50,762
and what we heard back
was something awesome,

78
00:03:50,762 --> 00:03:53,286
as someone trying
to bring a product into the world.

79
00:03:53,286 --> 00:03:55,211
Every one of them told us they loved it.

80
00:03:55,211 --> 00:03:58,777
In fact, we had a Porsche driver
who came in and told us on the first day,

81
00:03:58,777 --> 00:04:01,440
"This is completely stupid.
What are we thinking?"

82
00:04:01,850 --> 00:04:04,690
But at the end of it, he said,
"Not only should I have it,

83
00:04:04,690 --> 00:04:07,865
everyone else should have it,
because people are terrible drivers."

84
00:04:09,135 --> 00:04:10,870
So this was music to our ears,

85
00:04:10,870 --> 00:04:14,673
but then we started to look at what
the people inside the car were doing,

86
00:04:14,673 --> 00:04:16,252
and this was eye-opening.

87
00:04:16,252 --> 00:04:18,690
Now, my favorite story is this gentleman

88
00:04:18,690 --> 00:04:22,519
who looks down at his phone
and realizes the battery is low,

89
00:04:22,519 --> 00:04:27,067
so he turns around like this in the car
and digs around in his backpack,

90
00:04:27,067 --> 00:04:29,220
pulls out his laptop,

91
00:04:29,220 --> 00:04:30,787
puts it on the seat,

92
00:04:30,787 --> 00:04:32,551
goes in the back again,

93
00:04:32,551 --> 00:04:35,918
digs around, pulls out
the charging cable for his phone,

94
00:04:35,918 --> 00:04:39,285
futzes around, puts it into the laptop,
puts it on the phone.

95
00:04:39,285 --> 00:04:41,328
Sure enough, the phone is charging.

96
00:04:41,328 --> 00:04:45,322
All the time he's been doing
65 miles per hour down the freeway.

97
00:04:45,322 --> 00:04:47,806
Right? Unbelievable.

98
00:04:47,806 --> 00:04:50,927
So we thought about this and we said,
it's kind of obvious, right?

99
00:04:50,927 --> 00:04:53,190
The better the technology gets,

100
00:04:53,190 --> 00:04:55,311
the less reliable
the driver is going to get.

101
00:04:55,311 --> 00:04:57,707
So by just making the cars
incrementally smarter,

102
00:04:57,707 --> 00:05:00,609
we're probably not going to see
the wins we really need.

103
00:05:00,609 --> 00:05:04,510
Let me talk about something
a little technical for a moment here.

104
00:05:04,510 --> 00:05:06,948
So we're looking at this graph,
and along the bottom

105
00:05:06,948 --> 00:05:09,999
is how often does the car
apply the brakes when it shouldn't.

106
00:05:09,999 --> 00:05:11,620
You can ignore most of that axis,

107
00:05:11,620 --> 00:05:15,339
because if you're driving around town,
and the car starts stopping randomly,

108
00:05:15,339 --> 00:05:17,040
you're never going to buy that car.

109
00:05:17,040 --> 00:05:20,415
And the vertical axis is how often
the car is going to apply the brakes

110
00:05:20,415 --> 00:05:23,464
when it's supposed to
to help you avoid an accident.

111
00:05:23,464 --> 00:05:25,685
Now, if we look at
the bottom left corner here,

112
00:05:25,685 --> 00:05:27,530
this is your classic car.

113
00:05:27,530 --> 00:05:30,663
It doesn't apply the brakes for you,
it doesn't do anything goofy,

114
00:05:30,663 --> 00:05:33,442
but it also doesn't get you
out of an accident.

115
00:05:33,442 --> 00:05:36,460
Now, if we want to bring
a driver assistance system into a car,

116
00:05:36,460 --> 00:05:38,288
say with collision mitigation braking,

117
00:05:38,288 --> 00:05:40,900
we're going to put some package
of technology on there,

118
00:05:40,900 --> 00:05:44,318
and that's this curve, and it's going
to have some operating properties,

119
00:05:44,318 --> 00:05:46,808
but it's never going to avoid
all of the accidents,

120
00:05:46,808 --> 00:05:48,867
because it doesn't have that capability.

121
00:05:48,867 --> 00:05:51,116
But we'll pick some place
along the curve here,

122
00:05:51,116 --> 00:05:54,370
and maybe it avoids half of accidents
that the human driver misses,

123
00:05:54,370 --> 00:05:55,667
and that's amazing, right?

124
00:05:55,667 --> 00:05:58,394
We just reduced accidents on our roads
by a factor of two.

125
00:05:58,394 --> 00:06:02,381
There are now 17,000 less people
dying every year in America.

126
00:06:02,381 --> 00:06:04,401
But if we want a self-driving car,

127
00:06:04,401 --> 00:06:06,708
we need a technology curve
that looks like this.

128
00:06:06,708 --> 00:06:09,307
We're going to have to put
more sensors in the vehicle,

129
00:06:09,307 --> 00:06:11,328
and we'll pick some
operating point up here

130
00:06:11,328 --> 00:06:13,347
where it basically never
gets into a crash.

131
00:06:13,347 --> 00:06:15,790
They'll happen, but very low frequency.

132
00:06:15,790 --> 00:06:18,251
Now you and I could look at this
and we could argue

133
00:06:18,251 --> 00:06:21,856
about whether it's incremental, and
I could say something like "80-20 rule,"

134
00:06:21,856 --> 00:06:24,424
and it's really hard to move up
to that new curve.

135
00:06:24,424 --> 00:06:27,358
But let's look at it
from a different direction for a moment.

136
00:06:27,358 --> 00:06:30,870
So let's look at how often
the technology has to do the right thing.

137
00:06:30,870 --> 00:06:34,376
And so this green dot up here
is a driver assistance system.

138
00:06:34,376 --> 00:06:36,861
It turns out that human drivers

139
00:06:36,861 --> 00:06:39,508
make mistakes that lead
to traffic accidents

140
00:06:39,508 --> 00:06:42,680
about once every 100,000 miles in America.

141
00:06:42,680 --> 00:06:45,847
In contrast, a self-driving system
is probably making decisions

142
00:06:45,847 --> 00:06:49,510
about 10 times per second,

143
00:06:49,510 --> 00:06:50,932
so order of magnitude,

144
00:06:50,932 --> 00:06:53,764
that's about 1,000 times per mile.

145
00:06:53,764 --> 00:06:56,249
So if you compare the distance
between these two,

146
00:06:56,249 --> 00:06:58,849
it's about 10 to the eighth, right?

147
00:06:58,849 --> 00:07:00,614
Eight orders of magnitude.

148
00:07:00,614 --> 00:07:03,423
That's like comparing how fast I run

149
00:07:03,423 --> 00:07:05,629
to the speed of light.

150
00:07:05,629 --> 00:07:09,414
It doesn't matter how hard I train,
I'm never actually going to get there.

151
00:07:09,414 --> 00:07:11,852
So there's a pretty big gap there.

152
00:07:11,852 --> 00:07:15,581
And then finally, there's how
the system can handle uncertainty.

153
00:07:15,581 --> 00:07:18,904
So this pedestrian here might be
stepping into the road, might not be.

154
00:07:18,904 --> 00:07:22,299
I can't tell,
nor can any of our algorithms,

155
00:07:22,310 --> 00:07:24,594
but in the case of
a driver assistance system,

156
00:07:24,594 --> 00:07:27,400
that means it can't take action,
because again,

157
00:07:27,400 --> 00:07:30,739
if it presses the brakes unexpectedly,
that's completely unacceptable.

158
00:07:30,739 --> 00:07:33,872
Whereas a self-driving system
can look at that pedestrian and say,

159
00:07:33,872 --> 00:07:35,762
I don't know what they're about to do,

160
00:07:35,762 --> 00:07:39,524
slow down, take a better look,
and then react appropriately after that.

161
00:07:39,524 --> 00:07:43,226
So it can be much safer than
a driver assistance system can ever be.

162
00:07:43,226 --> 00:07:45,956
So that's enough about
the differences between the two.

163
00:07:45,956 --> 00:07:49,440
Let's spend some time talking about
how the car sees the world.

164
00:07:49,440 --> 00:07:50,692
So this is our vehicle.

165
00:07:50,692 --> 00:07:53,130
It starts by understanding
where it is in the world,

166
00:07:53,130 --> 00:07:55,917
by taking a map and its sensor data
and aligning the two,

167
00:07:55,917 --> 00:07:58,865
and then we layer on top of that
what it sees in the moment.

168
00:07:58,865 --> 00:08:02,520
So here, all the purple boxes you can see
are other vehicles on the road,

169
00:08:02,520 --> 00:08:05,048
and the red thing on the side
over there is a cyclist,

170
00:08:05,048 --> 00:08:07,450
and up in the distance,
if you look really closely,

171
00:08:07,450 --> 00:08:09,244
you can see some cones.

172
00:08:09,244 --> 00:08:12,017
Then we know where the car
is in the moment,

173
00:08:12,017 --> 00:08:15,850
but we have to do better than that:
we have to predict what's going to happen.

174
00:08:15,850 --> 00:08:19,338
So here the pickup truck in top right
is about to make a left lane change

175
00:08:19,338 --> 00:08:21,561
because the road in front of it is closed,

176
00:08:21,561 --> 00:08:23,292
so it needs to get out of the way.

177
00:08:23,292 --> 00:08:25,155
Knowing that one pickup truck is great,

178
00:08:25,155 --> 00:08:27,634
but we really need to know
what everybody's thinking,

179
00:08:27,634 --> 00:08:30,141
so it becomes quite a complicated problem.

180
00:08:30,141 --> 00:08:34,890
And then given that, we can figure out
how the car should respond in the moment,

181
00:08:34,890 --> 00:08:38,756
so what trajectory it should follow, how
quickly it should slow down or speed up.

182
00:08:38,756 --> 00:08:41,821
And then that all turns into
just following a path:

183
00:08:41,821 --> 00:08:45,018
turning the steering wheel left or right,
pressing the brake or gas.

184
00:08:45,018 --> 00:08:47,482
It's really just two numbers
at the end of the day.

185
00:08:47,482 --> 00:08:49,723
So how hard can it really be?

186
00:08:50,433 --> 00:08:52,385
Back when we started in 2009,

187
00:08:52,385 --> 00:08:54,183
this is what our system looked like.

188
00:08:54,183 --> 00:08:57,574
So you can see our car in the middle
and the other boxes on the road,

189
00:08:57,574 --> 00:08:58,845
driving down the highway.

190
00:08:58,845 --> 00:09:02,663
The car needs to understand where it is
and roughly where the other vehicles are.

191
00:09:02,663 --> 00:09:05,092
It's really a geometric
understanding of the world.

192
00:09:05,092 --> 00:09:08,040
Once we started driving
on neighborhood and city streets,

193
00:09:08,040 --> 00:09:10,485
the problem becomes a whole
new level of difficulty.

194
00:09:10,485 --> 00:09:13,979
You see pedestrians crossing in front
of us, cars crossing in front of us,

195
00:09:13,979 --> 00:09:15,790
going every which way,

196
00:09:15,790 --> 00:09:17,317
the traffic lights, crosswalks.

197
00:09:17,317 --> 00:09:20,114
It's an incredibly complicated
problem by comparison.

198
00:09:20,114 --> 00:09:22,217
And then once you have
that problem solved,

199
00:09:22,217 --> 00:09:24,729
the vehicle has to be able
to deal with construction.

200
00:09:24,729 --> 00:09:27,880
So here are the cones on the left
forcing it to drive to the right,

201
00:09:27,880 --> 00:09:30,282
but not just construction
in isolation, of course.

202
00:09:30,282 --> 00:09:34,005
It has to deal with other people moving
through that construction zone as well.

203
00:09:34,005 --> 00:09:37,268
And of course, if anyone's
breaking the rules, the police are there

204
00:09:37,268 --> 00:09:40,890
and the car has to understand that
that flashing light on the top of the car

205
00:09:40,890 --> 00:09:43,995
means that it's not just a car,
it's actually a police officer.

206
00:09:43,995 --> 00:09:46,027
Similarly, the orange box
on the side here,

207
00:09:46,027 --> 00:09:47,136
it's a school bus,

208
00:09:47,136 --> 00:09:49,656
and we have to treat that
differently as well.

209
00:09:50,576 --> 00:09:53,369
When we're out on the road,
other people have expectations:

210
00:09:53,369 --> 00:09:55,149
So, when a cyclist puts up their arm,

211
00:09:55,149 --> 00:09:58,667
it means they're expecting the car
to yield to them and make room for them

212
00:09:58,667 --> 00:10:00,720
to make a lane change.

213
00:10:01,030 --> 00:10:03,203
And when a police officer
stood in the road,

214
00:10:03,203 --> 00:10:05,943
our vehicle should understand
that this means stop,

215
00:10:05,943 --> 00:10:09,449
and when they signal to go,
we should continue.

216
00:10:09,449 --> 00:10:13,210
Now, the way we accomplish this
is by sharing data between the vehicles.

217
00:10:13,210 --> 00:10:14,906
The first, most crude model of this

218
00:10:14,906 --> 00:10:17,019
is when one vehicle
sees a construction zone,

219
00:10:17,019 --> 00:10:20,081
having another know about it
so it can be in the correct lane

220
00:10:20,081 --> 00:10:21,651
to avoid some of the difficulty.

221
00:10:21,651 --> 00:10:24,315
But we actually have a much
deeper understanding of this.

222
00:10:24,315 --> 00:10:27,324
We could take all of the data
that the cars have seen over time,

223
00:10:27,324 --> 00:10:29,700
the hundreds of thousands
of pedestrians, cyclists,

224
00:10:29,700 --> 00:10:31,487
and vehicles that have been out there

225
00:10:31,487 --> 00:10:33,182
and understand what they look like

226
00:10:33,182 --> 00:10:36,013
and use that to infer
what other vehicles should look like

227
00:10:36,013 --> 00:10:37,939
and other pedestrians should look like.

228
00:10:37,939 --> 00:10:40,960
And then, even more importantly,
we could take from that a model

229
00:10:40,960 --> 00:10:43,290
of how we expect them
to move through the world.

230
00:10:43,290 --> 00:10:46,253
So here the yellow box is a pedestrian
crossing in front of us.

231
00:10:46,253 --> 00:10:48,503
Here the blue box is a cyclist
and we anticipate

232
00:10:48,503 --> 00:10:51,815
that they're going to nudge out
and around the car to the right.

233
00:10:52,115 --> 00:10:54,207
Here there's a cyclist
coming down the road

234
00:10:54,207 --> 00:10:57,693
and we know they're going to continue
to drive down the shape of the road.

235
00:10:57,693 --> 00:10:59,560
Here somebody makes a right turn,

236
00:10:59,560 --> 00:11:02,920
and in a moment here, somebody's
going to make a U-turn in front of us,

237
00:11:02,920 --> 00:11:05,534
and we can anticipate that behavior
and respond safely.

238
00:11:05,534 --> 00:11:08,262
Now, that's all well and good
for things that we've seen,

239
00:11:08,262 --> 00:11:11,127
but of course, you encounter
lots of things that you haven't

240
00:11:11,127 --> 00:11:12,358
seen in the world before.

241
00:11:12,358 --> 00:11:14,099
And so just a couple of months ago,

242
00:11:14,099 --> 00:11:16,334
our vehicles were driving
through Mountain View,

243
00:11:16,334 --> 00:11:17,978
and this is what we encountered.

244
00:11:17,978 --> 00:11:20,060
This is a woman in an electric wheelchair

245
00:11:20,060 --> 00:11:22,677
chasing a duck in circles on the road.
(Laughter)

246
00:11:22,677 --> 00:11:25,788
Now it turns out, there is nowhere
in the DMV handbook

247
00:11:25,788 --> 00:11:28,033
that tells you how to deal with that,

248
00:11:28,033 --> 00:11:30,176
but our vehicles were able
to encounter that,

249
00:11:30,176 --> 00:11:32,431
slow down, and drive safely.

250
00:11:32,431 --> 00:11:34,472
Now, we don't have to deal
with just ducks.

251
00:11:34,472 --> 00:11:38,180
Watch this bird fly across in front of us.
The car reacts to that.

252
00:11:38,180 --> 00:11:39,795
Here we're dealing with a cyclist

253
00:11:39,795 --> 00:11:43,085
that you would never expect to see
anywhere other than Mountain View.

254
00:11:43,085 --> 00:11:45,153
And of course, we have
to deal with drivers,

255
00:11:45,153 --> 00:11:48,868
even the very small ones.

256
00:11:48,868 --> 00:11:52,999
Watch to the right as someone
jumps out of this truck at us.

257
00:11:54,460 --> 00:11:57,389
And now, watch the left as the car
with the green box decides

258
00:11:57,389 --> 00:12:00,714
he needs to make a right turn
at the last possible moment.

259
00:12:00,714 --> 00:12:03,565
Here, as we make a lane change,
the car to our left decides

260
00:12:03,565 --> 00:12:07,118
it wants to as well.

261
00:12:07,118 --> 00:12:09,811
And here, we watch a car
blow through a red light

262
00:12:09,811 --> 00:12:11,901
and yield to it.

263
00:12:11,901 --> 00:12:15,755
And similarly, here, a cyclist
blowing through that light as well.

264
00:12:15,755 --> 00:12:18,501
And of course,
the vehicle responds safely.

265
00:12:18,501 --> 00:12:21,102
And of course, we have people
who do I don't know what

266
00:12:21,102 --> 00:12:24,925
sometimes on the road, like this guy
pulling out between two self-driving cars.

267
00:12:24,925 --> 00:12:26,970
You have to ask, "What are you thinking?"

268
00:12:26,970 --> 00:12:28,182
(Laughter)

269
00:12:28,182 --> 00:12:30,703
Now, I just fire-hosed you
with a lot of stuff there,

270
00:12:30,703 --> 00:12:33,353
so I'm going to break one of these
down pretty quickly.

271
00:12:33,353 --> 00:12:36,293
So what we're looking at is the scene
with the cyclist again,

272
00:12:36,293 --> 00:12:39,784
and you might notice in the bottom,
we can't actually see the cyclist yet,

273
00:12:39,784 --> 00:12:42,288
but the car can: it's that little
blue box up there,

274
00:12:42,288 --> 00:12:44,369
and that comes from the laser data.

275
00:12:44,369 --> 00:12:46,787
And that's not actually
really easy to understand,

276
00:12:46,787 --> 00:12:50,371
so what I'm going to do is I'm going
to turn that laser data and look at it,

277
00:12:50,371 --> 00:12:53,400
and if you're really good at looking
at laser data, you can see

278
00:12:53,400 --> 00:12:54,887
a few dots on the curve there,

279
00:12:54,887 --> 00:12:57,259
right there, and that blue box
is that cyclist.

280
00:12:57,259 --> 00:12:58,408
Now as our light is red,

281
00:12:58,408 --> 00:13:00,600
the cyclist's light
has turned yellow already,

282
00:13:00,600 --> 00:13:03,038
and if you squint, you can see that
in the imagery.

283
00:13:03,038 --> 00:13:06,324
But the cyclist, we see, is going
to proceed through the intersection.

284
00:13:06,324 --> 00:13:08,718
Our light has now turned green,
his is solidly red,

285
00:13:08,718 --> 00:13:13,010
and we now anticipate that this bike
is going to come all the way across.

286
00:13:13,010 --> 00:13:16,752
Unfortunately the other drivers next to us
were not paying as much attention.

287
00:13:16,752 --> 00:13:19,909
They started to pull forward,
and fortunately for everyone,

288
00:13:19,909 --> 00:13:22,920
this cyclists reacts, avoids,

289
00:13:22,920 --> 00:13:25,111
and makes it through the intersection.

290
00:13:25,111 --> 00:13:26,679
And off we go.

291
00:13:26,679 --> 00:13:29,627
Now, as you can see, we've made
some pretty exciting progress,

292
00:13:29,627 --> 00:13:31,529
and at this point we're pretty convinced

293
00:13:31,529 --> 00:13:33,539
this technology is going
to come to market.

294
00:13:33,539 --> 00:13:38,322
We do three million miles of testing
in our simulators every single day,

295
00:13:38,322 --> 00:13:41,011
so you can imagine the experience
that our vehicles have.

296
00:13:41,011 --> 00:13:43,875
We are looking forward to having
this technology on the road,

297
00:13:43,875 --> 00:13:46,765
and we think the right path
is to go through the self-driving

298
00:13:46,765 --> 00:13:48,609
rather than driver assistance approach

299
00:13:48,609 --> 00:13:51,230
because the urgency is so large.

300
00:13:51,230 --> 00:13:53,623
In the time I have given this talk today,

301
00:13:53,623 --> 00:13:56,758
34 people have died on America's roads.

302
00:13:56,758 --> 00:13:59,126
How soon can we bring it out?

303
00:13:59,126 --> 00:14:02,958
Well, it's hard to say because
it's a really complicated problem,

304
00:14:02,958 --> 00:14:05,172
but these are my two boys.

305
00:14:05,172 --> 00:14:08,795
My oldest son is 11, and that means
in four and a half years,

306
00:14:08,795 --> 00:14:11,372
he's going to be able
to get his driver's license.

307
00:14:11,372 --> 00:14:14,576
My team and I are committed
to making sure that doesn't happen.

308
00:14:14,576 --> 00:14:16,480
Thank you.

309
00:14:16,480 --> 00:14:20,147
(Laughter) (Applause)

310
00:14:21,110 --> 00:14:23,678
Chris Anderson: Chris,
I've got a question for you.

311
00:14:23,678 --> 00:14:26,487
Chris Urmson: Sure.

312
00:14:26,487 --> 00:14:30,411
CA: So certainly, the mind of your cars
is pretty mind-boggling.

313
00:14:30,411 --> 00:14:34,870
On this debate between
driver-assisted and fully driverless --

314
00:14:34,870 --> 00:14:37,911
I mean, there's a real debate
going on out there right now.

315
00:14:37,911 --> 00:14:40,744
So some of the companies,
for example, Tesla,

316
00:14:40,744 --> 00:14:42,903
are going the driver-assisted route.

317
00:14:42,903 --> 00:14:48,151
What you're saying is that
that's kind of going to be a dead end

318
00:14:48,151 --> 00:14:53,607
because you can't just keep improving
that route and get to fully driverless

319
00:14:53,607 --> 00:14:57,137
at some point, and then a driver
is going to say, "This feels safe,"

320
00:14:57,137 --> 00:14:59,784
and climb into the back,
and something ugly will happen.

321
00:14:59,784 --> 00:15:02,460
CU: Right. No, that's exactly right,
and it's not to say

322
00:15:02,460 --> 00:15:05,997
that the driver assistance systems
aren't going to be incredibly valuable.

323
00:15:05,997 --> 00:15:08,055
They can save a lot of lives
in the interim,

324
00:15:08,055 --> 00:15:11,888
but to see the transformative opportunity
to help someone like Steve get around,

325
00:15:11,888 --> 00:15:13,857
to really get to the end case in safety,

326
00:15:13,857 --> 00:15:16,336
to have the opportunity
to change our cities

327
00:15:16,336 --> 00:15:20,540
and move parking out and get rid of
these urban craters we call parking lots,

328
00:15:20,540 --> 00:15:21,780
it's the only way to go.

329
00:15:21,780 --> 00:15:24,498
CA: We will be tracking your progress
with huge interest.

330
00:15:24,498 --> 00:15:28,730
Thanks so much, Chris.
CU: Thank you. (Applause)
